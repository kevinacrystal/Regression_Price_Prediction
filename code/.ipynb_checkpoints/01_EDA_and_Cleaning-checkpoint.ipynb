{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the train set and assign it to 'df'\n",
    "df = pd.read_csv('../datasets/train.csv')\n",
    "# import the test set and assign it to 'holdout'\n",
    "holdout = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the shape of the training data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset contains 2,051 rows (each row represents a house sold) and 81 columns (each column represents a feature, or characteristic of the house)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display the shape of the holdout data\n",
    "holdout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The holdout dataset contains 879 rows and 80 columns. The target column, sales price, has been removed from the holdout dataset.\n",
    "\n",
    "Together, the testing and holdout sets describe 2,930 houses; these have been split so that 70 percent are in the training set and 30 percent are in the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 5 rows of the training data using df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each house is described in great detail. It will take some investigation to determine the extent to which each feature can be used in developing a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Columns\n",
    "\n",
    "Before I work with them, I like to rename columns to eliminate capital letters and replace spaces with underscores. For me, this makes it easier to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces in column names with underscores\n",
    "# and convert all to lowercase\n",
    "df.columns = [x.replace(\" \", \"_\").lower() for x in df.columns]\n",
    "holdout.columns = [x.replace(\" \", \"_\").lower() for x in holdout.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Missingness and Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate general information about the dataset using df.info()\n",
    "# this includes inormation on the number of nulls in each column\n",
    "# and the datatype of each column.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two key takeaways from this:\n",
    "\n",
    "1. There are many null values, which will throw errors during modeling if they're not addressed. \n",
    "\n",
    "2. 42 of the columns are stored as objects, which will need to be changed to numeric types, if possible, in order to be used in modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Values\n",
    "\n",
    "I will have to systematically go through the columns with nulls to address them, so I will define a simple function to display all of the nulls in descending order (most nulls shown first) by calling the function on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to return all the null values in descending order\n",
    "def check_nulls(dataframe):\n",
    "    nulls = dataframe.isnull().sum().sort_values(ascending=False)\n",
    "    return nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the number of nulls for all columns with nulls\n",
    "check_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls on the holdout set\n",
    "check_nulls(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are huge percentages. In order to get a better sense of which columns I might want to drop entirely, I'd also like to see the number of nulls as a percentage of the total observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the percentage of nulls for all columns with null percentage over 25%\n",
    "nulls = df.isnull().sum().sort_values(ascending=False)\n",
    "nulls[nulls / df.shape[0] > 0.25] / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These five features seem to be missing data for more than 25 percent of their observations, making them candidates to be dropped entirely, but the data dictionary suggestst that an NA value for these categories means that the specified feature is missing from the home (e.g. a home with an NA for pool_qc does not have a pool). A few options exist:\n",
    "\n",
    "1. *Drop the columns entirely*\n",
    "2. *Impute values of zero where the feature is specified as ordinal (pool_qc, alley, fence, fireplace_qu)*\n",
    "3. *Binarize the columns that indicate the presence or non-presence of the feature (e.g. impute a 1 if the property has a pool and a 0 if it doesn't have a pool)*\n",
    "\n",
    "In the interest of simplicity, I'm going to drop the four columns with greater than 80% null values. In the future it would be interesting to reconsider this for some or all of these columns.\n",
    "\n",
    "I'll also have to drop these from the holdout set, since the model will expect the number of input features to be the same when applied to the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to drop\n",
    "# I'll also drop 'pid' since it's an arbitrary identification number\n",
    "drop_columns = ['pool_qc', 'misc_feature', 'alley', 'fence', 'pid']\n",
    "\n",
    "# drop columns with over 80% null values in the training and holdout sets\n",
    "df.drop(columns=drop_columns, inplace=True)\n",
    "holdout.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Non-Numeric Columns (Ordinal Values to Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data dictionary, many of the non_numeric columns have ordinal values. For example, the column describing basement quality (basement height) includes the following values:    \n",
    "   \n",
    "   - Ex   Excellent (100+ inches) \n",
    "   - Gd   Good (90-99 inches)\n",
    "   - TA   Typical (80-89 inches)\n",
    "   - Fa   Fair (70-79 inches)\n",
    "   - Po   Poor (&lt;70 inches\n",
    "   - NA   No Basement \n",
    "\n",
    "Thus I will assign numerical values to these ratings, such that \"Ex\" is converted to 5, \"Gd\" is converted to 4, and so on through to \"NA\" being assigned to 0. This should have the secondary benefit of removing some of the remaining null values from these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to convert the ordinal columns \n",
    "# with the Ex-Gd-TA-Fa-Po-NA scale to numeric\n",
    "def ex_scale(df, column_list):\n",
    "    for column in column_list:\n",
    "        # replace ordinal objects with ordinal numbers\n",
    "        df[column] = df[column].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "        # convert columns from object to numeric datatype\n",
    "        df[column] = pd.to_numeric(df[column])\n",
    "        # replace null values with 0\n",
    "        df[column] = df[column].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the ex_scale function on the appropriate ordinal columns\n",
    "column_list = ['bsmt_qual', \n",
    "               'bsmt_cond',\n",
    "               'exter_qual',\n",
    "               'exter_cond',\n",
    "               'fireplace_qu',\n",
    "               'garage_qual',\n",
    "               'garage_cond',\n",
    "               'heating_qc',\n",
    "               'kitchen_qual']\n",
    "ex_scale(df, column_list)\n",
    "ex_scale(holdout, column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional ordinal characterstics specified in the data dictionary have to be converted in a more piecemeal fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to streamline the process and apply the changes\n",
    "# to both the testing and the holdout sets\n",
    "def var_scale(column, reassign_dict, data_set_list = [df, holdout]):\n",
    "    for data_set in data_set_list:\n",
    "        data_set[column] = pd.to_numeric(data_set[column].map(reassign_dict))\n",
    "        data_set[column] = data_set[column].fillna(0)\n",
    "        #print(data_set[column].value_counts().sum())     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert additional ordinal characteristics\n",
    "var_scale('lot_shape', {'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0})\n",
    "var_scale('utilities', {'AllPub': 3, 'NoSewr': 2, 'NoSeWa': 1, 'ELO': 0})\n",
    "var_scale('land_slope', {'Gtl': 2, 'Mod': 1, 'Sev': 0})\n",
    "var_scale('bsmt_exposure', {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0})\n",
    "var_scale('bsmtfin_type_1', {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0})\n",
    "var_scale('bsmtfin_type_2', {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0})\n",
    "var_scale('electrical', {'SBrkr': 4, 'FuseA': 3, 'FuseF': 2, 'FuseP': 1, 'Mix': 0})\n",
    "var_scale('functional', {'Typ': 7, 'Min1': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'Sal': 0})\n",
    "var_scale('garage_finish', {'Fin': 3, 'Rfn': 2, 'Unf': 1})\n",
    "var_scale('paved_drive', {'Y': 2, 'P': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert binary 'central_air' column to 1 for yes, 0 for no\n",
    "df['central_air'] = pd.to_numeric(df.central_air.map({'Y': 1, 'N': 0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Non-Numeric Columns (Non-Ordinal Values to Dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the remaining non-numeric columns.\n",
    "# these are the columns that could not be converted based on ordinal scales\n",
    "non_ordinal_columns = [col for col in df.select_dtypes(include='object')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert non-ordinal columns to dummies for the test set\n",
    "df = pd.get_dummies(df, columns=non_ordinal_columns, drop_first=True)\n",
    "\n",
    "# convert non-ordinal columns to dummies for the holdout set\n",
    "holdout = pd.get_dummies(holdout, columns=non_ordinal_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-check Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls on test set\n",
    "nulls = df.isnull().sum().sort_values(ascending=False)\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls on holdout set\n",
    "nulls = holdout.isnull().sum().sort_values(ascending=False)\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### garage_yr_built Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the rows for which garage_yr_built is null\n",
    "# to see if there are actually any garages there\n",
    "garage_df = df[[col for col in df.columns if 'garage' in col]]\n",
    "garage_df[(df.garage_yr_blt.isnull()) & (df.garage_qual != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that a 'garage_qual' value of zero means there is no garage. Since there's no year value I can impute for houses with no garage, and there is a lot of other garage information that can contribute to the impact of the garage on the final model, I am going to drop 'garage_yr_blt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop garage_yr_blt from both the training set and the holdout set\n",
    "df.drop(columns='garage_yr_blt', inplace=True)\n",
    "holdout.drop(columns='garage_yr_blt', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mas_vnr_area Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the rows for which mas_vnr_area is null\n",
    "masonry_df = df[[col for col in df.columns if 'mas_' in col]]\n",
    "masonry_df[df.mas_vnr_area.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no values for any of the veneer types, so I will impute an area of zero for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the nulls with zeroes\n",
    "df['mas_vnr_area'] = df.mas_vnr_area.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the rows for which mas_vnr_area is null (holdout)\n",
    "masonry_df = holdout[[col for col in holdout.columns if 'mas_' in col]]\n",
    "masonry_df[holdout.mas_vnr_area.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute a value of zero for the holdout set's null value\n",
    "holdout['mas_vnr_area'] = holdout.mas_vnr_area.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check remaining nulls for test set\n",
    "check_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check remaining nulls for holdout set\n",
    "check_nulls(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute Missing lot_frontage Values with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_not_null = df[df.lot_frontage.notnull()].dropna()\n",
    "X = lot_not_null.drop(columns=['lot_frontage', 'id'])\n",
    "y = lot_not_null.lot_frontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "print('train score: ', lr.score(X_train_sc, y_train))\n",
    "print('test score: ', lr.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a terrible test score. Better try regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(X_train_sc, y_train)\n",
    "print('train score: ', lasso.score(X_train_sc, y_train))\n",
    "print('test score: ', lasso.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X_train_sc, y_train)\n",
    "print('train_score: ', ridge.score(X_train_sc, y_train))\n",
    "print('test_score: ', ridge.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso has the best r2 scores, so I'm going to use this to impute the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_null = df[df.lot_frontage.isnull()]\n",
    "lot_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_null.drop(columns=['lot_frontage', 'id'], inplace=True)\n",
    "lot_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_null_sc = ss.transform(lot_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lasso.predict(lot_null_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_lot_indices = list(df[df.lot_frontage.isnull()].index)\n",
    "for j,i in enumerate(null_lot_indices):\n",
    "    df.loc[i, 'lot_frontage'] = preds[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lot_frontage[null_lot_indices].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the row, since there is an entry that say the property has a 'detached' garage, and therefore I can't impute any info about the garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([1712], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'total_bsmt_sf'\n",
    "#### Find Training row with null value for 'total_bsmt_sf'\n",
    "I may want to use this as a feature, since it has a high correlation with the the target (0.63), and I believe I can infer that the building has no basement if the other basement columns imply that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['total_bsmt_sf'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute a value of 0 for total_bsmt_sf, since I believe this property has no basement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_value(1327, 'total_bsmt_sf', 0)\n",
    "df.loc[1327]['total_bsmt_sf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop remaining null values in train set\n",
    "There are few enough null columns left to remove them without seriously affecting out train set (22 of 2051 is about 1 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df.isnull().sum().sort_values(ascending=False)\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find remaining null values in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = holdout.isnull().sum().sort_values(ascending=False)\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout[holdout['mas_vnr_type'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this property has vinyl siding, I can infer that it does not have masonry veneer. I'll impute 'None' for mas_vnr_type and 0 for mas_vnr_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.set_value(866, 'mas_vnr_type', 'None')\n",
    "holdout.set_value(866, 'mas_vnr_area', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the summary statistics for the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(20, 12), bins = 20)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlations relative to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results = df.corr()[['saleprice']].sort_values('saleprice', ascending=False)\n",
    "corr_filter = corr_results[abs(corr_results.saleprice > 0.6)]\n",
    "corr_filter.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "sns.heatmap(corr_filter, annot=True, cmap = 'viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlations among the potential features\n",
    "  \n",
    "high correlations on:  \n",
    "- garage_area AND garage_cars\n",
    "- fireplaces AND fireplace_qu\n",
    "- garage_yr_built AND year_built\n",
    "- gr_live_area AND totrms_abvgrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "sns.heatmap(df[corr_filter.index].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.saleprice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our target variable is skewed right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.gr_liv_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above-Grade Living Area, one of our main input variables, has a couple of significant outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gr_liv_area > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.overall_qual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of one on Overall Quality is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.overall_qual == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned datasets to new csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/df_clean.csv')\n",
    "holdout.to_csv('../datasets/holdout_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
